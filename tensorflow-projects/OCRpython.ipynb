{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCRpython.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHjk+a/I/CaW5oz/A3nTF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreSlavescu/Tensorflow-Projects-and-Courses/blob/main/tensorflow-projects/OCRpython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBDEavux09wK"
      },
      "source": [
        "#Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GZGiiPg3lU8"
      },
      "source": [
        "###Build tesseract locally from this repository: \n",
        "https://github.com/tesseract-ocr/tessdoc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SehV45T0viei"
      },
      "source": [
        "!pip install tensorflow keras pytesseract tesseract pillow opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTZmg3ZrjCvP"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "import cv2 \n",
        "import PIL.Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqVRtgXo1D8q"
      },
      "source": [
        "#Config setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OaDbn8Z_yOqt",
        "outputId": "5ecbfddc-d1d8-49a2-cb73-b577b5a9377c"
      },
      "source": [
        "#Page Segmentation config\n",
        "\n",
        "\"\"\" \n",
        "0   Orientation and script detection only.\n",
        "1   Automatic page segmentation with OSD.\n",
        "2   Automatic page segmentation, but no OSD, or OCR.\n",
        "3   Fully automatic page segmentation, with no OSD/OCR. \n",
        "4   Single column of text variable sizes.\n",
        "5   Single uniform block of vertically aligned text.\n",
        "6   Single uniform block of text.\n",
        "7   Treat image as single text line.\n",
        "8   Treat image as single word.\n",
        "9   Treat image as single word within a circle.\n",
        "10  Treat image as single character.\n",
        "11  Unordered sparse text.\n",
        "12  sparse text with OSD.\n",
        "13  Treat image as a single text line, with tesseract-specific bypass\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\n0   Orientation and script detection only.\\n1   Automatic page segmentation with OSD.\\n2   Automatic page segmentation, but no OSD, or OCR.\\n3   Fully automatic page segmentation, with no OSD/OCR. \\n4   Single column of text variable sizes.\\n5   Single uniform block of vertically aligned text.\\n6   Single uniform block of text.\\n7   Treat image as single text line.\\n8   Treat image as single word.\\n9   Treat image as single word within a circle.\\n10  Treat image as single character.\\n11  Unordered sparse text.\\n12  sparse text with OSD.\\n13  Treat image as a single text line, with tesseract-specific bypass\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mFk42eKqx5j9",
        "outputId": "eecf5028-8466-406c-f7ed-265385a53200"
      },
      "source": [
        "#OCR config\n",
        "\n",
        "\"\"\"\n",
        "OCR Engine Mode\n",
        "0   Legacy engine only.\n",
        "1   Neural nets LSTM engine only.\n",
        "2   Legacy + LSTM engines.\n",
        "3   Default config\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nOCR Engine Mode\\n0   Legacy engine only.\\n1   Neural nets LSTM engine only.\\n2   Legacy + LSTM engines.\\n3   Default config\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_d-KoVgw6Kc"
      },
      "source": [
        "#modify config based on image parameters\n",
        "\n",
        "my_config = r\"--psm 6 --oem 3\"   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIv6Xzsu1IA3"
      },
      "source": [
        "#Optical Character Recognition modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgamZD4k1dZ1"
      },
      "source": [
        "###Select image number\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0WrNmsQ1boB",
        "outputId": "112625ff-c752-47c4-cd39-d726b90ddfd4"
      },
      "source": [
        "selection = int(input(\"pick an image number: \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pick an image number: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxn2rUiN02xM"
      },
      "source": [
        "###OCR with tesseract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAwqrkfbxVGt"
      },
      "source": [
        "#OCR with tesseract \n",
        "\n",
        "\"name images in this format: ocr{selection}.png\"\n",
        "\n",
        "img_to_text = pytesseract.image_to_string(PIL.Image.open(f\"ocr{selection}.png\"), config = my_config)\n",
        "print(img_to_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKrbbmyM1Mub"
      },
      "source": [
        "###OCR with openCV and tesseract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqhb7cg_1Qe2"
      },
      "source": [
        "#Uniform textbox module\n",
        "#optimal config: r\"--psm 6 --oem 3\"\n",
        "\n",
        "img = cv2.imread(f\"ocr{selection}.png\")\n",
        "height, width, _ = img.shape #taking height, width, and channel parameter (channel is not required)\n",
        "\n",
        "boxes = pytesseract.image_to_boxes(img, config = my_config)\n",
        "for box in boxes.splitlines():\n",
        "  box = box.split(\" \")\n",
        "  img = cv2.rectangle(img, (int(box[1]), height - int(box[2])), (int(box[3]), height - int(box[4])), (0, 255, 0), 2) #plot green rectangles around characters\n",
        "\n",
        "cv2.imshow(\"image\", img)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcxStoyN1h8c"
      },
      "source": [
        "#Image text recognition module\n",
        "#optimal config: r\"--psm 11 --oem 3\"\n",
        "\n",
        "img = cv2.imread(f\"ocr{selection}.png\")\n",
        "height, width, _ = img.shape #taking height, width, and channel parameter (channel is not required)\n",
        "\n",
        "data = pytesseract.image_to_boxes(img, config = my_config, output_type=Output.DICT)\n",
        "box_amount = len(data[\"text\"])\n",
        "for i in range(box_amount):\n",
        "  if float(data[\"conf\"][i]) > 85: #if confidence is above 85%, define a rectangle\n",
        "    (x, y, width, height) = (data[\"left\"][i], data[\"top\"])[i], data[\"width\"][i], data[\"height\"][i])\n",
        "    img = cv2.rectangle(img, (x, y), (x+width, y+height), (0, 255, 0), 2) #plot green rectangles around characters\n",
        "    img = cv2.putText(img, data[\"text\"][i], (x, y+height+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, ) #parameters: image, text data, translate text overlay, text font, scale, font color, thickness\n",
        "\n",
        "cv2.imshow(\"image\", img)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}